{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e305a3",
   "metadata": {},
   "source": [
    "# üèÜ AI-Driven LCA Tool - Hackathon Project\n",
    "**Goal**: Predict sustainability impact of metallurgical processes using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import libraries\n",
    "!pip install xgboost shap -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import joblib\n",
    "from google.colab import files\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72a0a4",
   "metadata": {},
   "source": [
    "## üìÇ Dataset Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd928caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and load dataset\n",
    "uploaded = files.upload()\n",
    "df = pd.read_csv('synthetic_LCA.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "display(df.head())\n",
    "display(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Categorical features: {df.select_dtypes(include='object').columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774ccd3",
   "metadata": {},
   "source": [
    "## üìä EDA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable analysis\n",
    "target = 'circularity_index'  # Our sustainability score\n",
    "print(f\"Target: {target} (Range: {df[target].min():.1f}-{df[target].max():.1f})\")\n",
    "\n",
    "# Key visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Target distribution\n",
    "axes[0,0].hist(df[target], bins=30, alpha=0.7, color='green')\n",
    "axes[0,0].set_title('Sustainability Score Distribution')\n",
    "\n",
    "# Key relationships\n",
    "axes[0,1].scatter(df['recycled_input_frac'], df[target], alpha=0.6)\n",
    "axes[0,1].set_title('Recycled Input vs Sustainability')\n",
    "\n",
    "axes[1,0].scatter(df['electricity_kWh'], df[target], alpha=0.6, color='red')\n",
    "axes[1,0].set_title('Electricity vs Sustainability')\n",
    "\n",
    "sns.boxplot(data=df, x='metal', y=target, ax=axes[1,1])\n",
    "axes[1,1].set_title('Sustainability by Metal Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "corr_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlated features\n",
    "target_corr = corr_matrix[target].abs().sort_values(ascending=False)\n",
    "print(\"\\nTop features correlated with sustainability:\")\n",
    "for feature, corr in target_corr.head(6).items():\n",
    "    if feature != target:\n",
    "        print(f\"‚Ä¢ {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc5d3a6",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meaningful derived features\n",
    "df_features = df.copy()\n",
    "\n",
    "# Efficiency ratios\n",
    "df_features['energy_intensity'] = df['electricity_kWh'] / df['mass_kg']\n",
    "df_features['circular_potential'] = (df['recycled_input_frac'] + df['end_of_life_recovery_frac']) / 2\n",
    "df_features['gwp_per_kg'] = df['GWP_kgCO2e'] / df['mass_kg']\n",
    "df_features['is_recycled'] = (df['route'] == 'recycled').astype(int)\n",
    "\n",
    "# Preprocessing\n",
    "df_features = df_features.fillna(df_features.median(numeric_only=True))\n",
    "df_encoded = pd.get_dummies(df_features, columns=['metal', 'route', 'transport_mode', 'alloy_grade'])\n",
    "\n",
    "# Prepare data\n",
    "X = df_encoded.drop(columns=['circularity_index', 'GWP_kgCO2e', 'energy_MJ'])\n",
    "y = df_encoded[target]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print(f\"Final dataset: {X_scaled.shape} features, {len(y)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aed2c7",
   "metadata": {},
   "source": [
    "## ü§ñ Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11adbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train multiple models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R¬≤': r2_score(y_test, y_pred)\n",
    "    }\n",
    "    trained_models[name] = model\n",
    "\n",
    "# Results comparison\n",
    "results_df = pd.DataFrame(results).T.round(4)\n",
    "print(\"üèÜ Model Performance:\")\n",
    "display(results_df.sort_values('R¬≤', ascending=False))\n",
    "\n",
    "best_model_name = results_df['R¬≤'].idxmax()\n",
    "best_model = trained_models[best_model_name]\n",
    "print(f\"\\nü•á Best Model: {best_model_name} (R¬≤ = {results_df.loc[best_model_name, 'R¬≤']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b165d",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148cecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Model comparison\n",
    "r2_scores = results_df['R¬≤'].sort_values()\n",
    "axes[0].barh(range(len(r2_scores)), r2_scores.values)\n",
    "axes[0].set_yticks(range(len(r2_scores)))\n",
    "axes[0].set_yticklabels(r2_scores.index)\n",
    "axes[0].set_title('Model Performance (R¬≤ Score)')\n",
    "axes[0].set_xlabel('R¬≤ Score')\n",
    "\n",
    "# Predicted vs Actual\n",
    "best_pred = best_model.predict(X_test)\n",
    "axes[1].scatter(y_test, best_pred, alpha=0.6)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1].set_xlabel('Actual')\n",
    "axes[1].set_ylabel('Predicted')\n",
    "axes[1].set_title(f'Predicted vs Actual ({best_model_name})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ef194",
   "metadata": {},
   "source": [
    "## üîç Feature Importance & SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "    plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "    plt.title(f'Top 10 Feature Importance ({best_model_name})')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# SHAP analysis\n",
    "if best_model_name in ['Random Forest', 'XGBoost']:\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test.sample(100, random_state=42))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_test.sample(100, random_state=42), \n",
    "                     plot_type=\"bar\", max_display=10, show=False)\n",
    "    plt.title('SHAP Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Top SHAP features:\")\n",
    "    mean_shap = np.abs(shap_values).mean(axis=0)\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'shap_value': mean_shap\n",
    "    }).sort_values('shap_value', ascending=False)\n",
    "    \n",
    "    for i, (_, row) in enumerate(shap_importance.head(5).iterrows(), 1):\n",
    "        print(f\"{i}. {row['feature']}: {row['shap_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b23782",
   "metadata": {},
   "source": [
    "## üí° Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insights\n",
    "print(\"üîç KEY INSIGHTS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Route impact\n",
    "route_impact = df.groupby('route')[target].mean()\n",
    "print(f\"Recycled route: {route_impact['recycled']:.1f} avg sustainability\")\n",
    "print(f\"Raw route: {route_impact['raw']:.1f} avg sustainability\")\n",
    "print(f\"Improvement potential: {route_impact['recycled'] - route_impact['raw']:.1f} points\")\n",
    "\n",
    "# Metal comparison\n",
    "metal_impact = df.groupby('metal')[target].mean()\n",
    "print(f\"\\nMetal comparison:\")\n",
    "for metal, score in metal_impact.items():\n",
    "    print(f\"‚Ä¢ {metal.title()}: {score:.1f} sustainability score\")\n",
    "\n",
    "print(f\"\\nüéØ RECOMMENDATIONS:\")\n",
    "print(\"1. Prioritize recycled content to boost sustainability\")\n",
    "print(\"2. Optimize energy efficiency (reduce electricity/kg)\")\n",
    "print(\"3. Improve end-of-life recovery systems\")\n",
    "print(\"4. Consider renewable energy sources\")\n",
    "print(\"5. Minimize transport distances\")\n",
    "\n",
    "print(f\"\\nü§ñ MODEL SUMMARY:\")\n",
    "print(f\"Best model explains {results_df.loc[best_model_name, 'R¬≤']:.1%} of sustainability variance\")\n",
    "print(f\"Prediction accuracy: ¬±{results_df.loc[best_model_name, 'MAE']:.1f} sustainability points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd819fbc",
   "metadata": {},
   "source": [
    "## üíæ Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c777c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and results\n",
    "joblib.dump(best_model, 'best_lca_model.joblib')\n",
    "joblib.dump(scaler, 'feature_scaler.joblib')\n",
    "results_df.to_csv('model_results.csv')\n",
    "\n",
    "print(\"‚úÖ Files saved:\")\n",
    "print(\"‚Ä¢ best_lca_model.joblib (trained model)\")\n",
    "print(\"‚Ä¢ feature_scaler.joblib (preprocessing)\")\n",
    "print(\"‚Ä¢ model_results.csv (performance metrics)\")\n",
    "\n",
    "# Download files\n",
    "files.download('best_lca_model.joblib')\n",
    "files.download('feature_scaler.joblib')\n",
    "files.download('model_results.csv')\n",
    "\n",
    "print(\"\\nüèÜ HACKATHON PROJECT COMPLETE!\")\n",
    "print(\"Successfully built AI model for LCA sustainability prediction\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
